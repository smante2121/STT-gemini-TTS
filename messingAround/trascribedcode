from flask import Flask, jsonify
from google.cloud import speech
import sounddevice as sd
from six.moves import queue
import os
app = Flask(__name__)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "stt-tts-428014-7f0bd529b23f.json"
# Audio recording parameters
RATE = 16000
CHUNK = int(RATE / 10)  # 100ms

class MicrophoneStream(object):
    """Opens a recording stream as a generator yielding the audio chunks."""
    def __init__(self, rate, chunk):
        self._rate = rate
        self._chunk = chunk

        # Create a thread-safe buffer of audio data
        self._buff = queue.Queue()
        self._closed = True

    def __enter__(self):
        self._closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._closed = True

    def generator(self):
        with sd.InputStream(samplerate=self._rate, channels=1, dtype='int16', blocksize=self._chunk) as stream:
            while not self._closed:
                data, overflowed = stream.read(self._chunk)
                if overflowed:
                    print("Audio buffer overflowed")
                self._buff.put(data.tobytes())
                yield self._buff.get()

def listen_print_loop(responses):
    num_chars_printed = 0
    for response in responses:
        if not response.results:
            continue

        result = response.results[0]
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript
        overwrite_chars = ' ' * (num_chars_printed - len(transcript))

        if not result.is_final:
            num_chars_printed = len(transcript)
        else:
            print(transcript + overwrite_chars)
            num_chars_printed = 0

@app.route('/transcribe')
def transcribe_stream():
    client = speech.SpeechClient()

    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="en-US",
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True,
    )

    with MicrophoneStream(RATE, CHUNK) as stream:
        audio_generator = stream.generator()
        requests = (speech.StreamingRecognizeRequest(audio_content=content)
                    for content in audio_generator)

        responses = client.streaming_recognize(streaming_config, requests)

        try:
            listen_print_loop(responses)
        except Exception as e:
            print(f"Error: {e}")

    return jsonify({"status": "transcription completed"})

if __name__ == '__main__':
    app.run(debug=True)