from flask import Flask, jsonify
import requests
from google.cloud import speech
import sounddevice as sd
from six.moves import queue
import os
from uuid import uuid4
import pathlib
import textwrap
from IPython.display import display
from IPython.display import Markdown
from google.cloud import aiplatform
import dotenv
import google.generativeai as genai
from google.generativeai import GenerativeModel

dotenv.load_dotenv()
GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

model=GenerativeModel('gemini-1.5-flash')
chat=model.start_chat(history=[])
GEMINI_API_URL = "https://api.gemini.ai/v1/messages"
session_id = str(uuid4())
app = Flask(__name__)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "stt-tts-428014-7f0bd529b23f.json"
# Audio recording parameters
RATE = 16000
CHUNK = int(RATE / 10)  # 100ms


def to_markdown(text):
    text = text.replace('•', '  *')
    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

class MicrophoneStream(object):
    """Opens a recording stream as a generator yielding the audio chunks."""
    def __init__(self, rate, chunk):
        self._rate = rate
        self._chunk = chunk
        # Create a thread-safe buffer of audio data
        self._buff = queue.Queue()
        self._closed = True

    def __enter__(self):
        self._closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._closed = True

    def generator(self):
        with sd.InputStream(samplerate=self._rate, channels=1, dtype='int16', blocksize=self._chunk) as stream:
            while not self._closed:
                data, overflowed = stream.read(self._chunk)
                if overflowed:
                    print("Audio buffer overflowed")
                self._buff.put(data.tobytes())
                yield self._buff.get()

def listen_print_loop(responses):
    #num_chars_printed = 0
    for response in responses:
        if not response.results:
            continue
        result = response.results[0]
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript
        #overwrite_chars = ' ' * (num_chars_printed - len(transcript))
        print(f'Transcribed: {transcript}')

        gemini_response = interact_with_gemini(transcript)
        print(f'Gemini says: {gemini_response}')
        return gemini_response

        #if not result.is_final:
            #num_chars_printed = len(transcript)
        #else:
            #print(transcript + overwrite_chars)
            #num_chars_printed = 0

@app.route('/transcribe')
def transcribe_stream():
    client = speech.SpeechClient()
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="en-US",
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True,
    )


    with MicrophoneStream(RATE, CHUNK) as stream:
        audio_generator = stream.generator()
        requests = (speech.StreamingRecognizeRequest(audio_content=content)
                    for content in audio_generator)
        responses = client.streaming_recognize(streaming_config, requests)
        for response in responses:
            for result in response.results:
                if result.is_final:
                    transcript = result.alternatives[0].transcript
                    print(f'Transcribed: {transcript}')  # Output to terminal
                    gemini_response = interact_with_gemini(transcript, session_id)
                    print(f'Gemini says: {gemini_response}')  # Gemini's simulated response
                    return jsonify({"transcript": transcript, "gemini_response": gemini_response})
    return jsonify({"status": "transcription completed"})


def interact_with_gemini(transcript, session_id):
    headers = {
        'Authorization': f'Bearer {os.getenv("GEMINI_API_KEY")}',
        'Content-Type': 'application/json'
    }
    payload = {
        'session_id': session_id,  # A unique identifier for the conversation session
        'input': transcript
    }
    response = requests.post(GEMINI_API_URL, json=payload, headers=headers)
    if response.status_code == 200:
        return response.json()['response']
    else:
        return "Sorry, I didn't understand that. Can you please repeat?"
    """Placeholder function to simulate sending transcript to Gemini and receiving a response."""
    # Here you would integrate the actual API call to Gemini
    responses = {
        "start": "Hello, let’s take a minute to collect some information to expedite your call. What is your callback number?",
        "What is your callback number?": "I have your callback number as {}. Is that correct?",
        "confirm_number": "Are you the patient?",
        "patient": "Great, could you please provide me with your date of birth?",
        "date_of_birth": "Could you please provide the first three letters of your last name?",
        "last_name": "Got it. Are you a biological male or female?",
        "gender": "What state are you in right now?",
        "state": "Perfect. In a few words, please tell me your main symptom or reason for the call today.",
        "symptom": "Give me a moment. We are all set, I’m connecting you with a live agent who will have this information."
    }
    # Simulate a response for demonstration purposes
    return responses.get(transcript, "Sorry, could you repeat that?")




if __name__ == '__main__':
    app.run(debug=True, ssl_context=('server.crt', 'server.key'))