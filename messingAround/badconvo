import numpy as np
from flask import Flask, jsonify
from google.cloud import speech
from google.cloud import texttospeech
import sounddevice as sd
from six.moves import queue
import os
import google.generativeai as genai
from dotenv import load_dotenv



app = Flask(__name__)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "stt-tts-428014-7f0bd529b23f.json"

load_dotenv()
GOOGLE_API_KEY= os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash', system_instruction='Respond as if you are a human having a conversation. Do not include emojis.')
chat=model.start_chat(history=[])


# Audio recording parameters
RATE = 16000 # sample rate, how often the audio signal is sampled per second
CHUNK = int(RATE / 10)  # 100ms # how many samples are in each chunk of audio data

class MicrophoneStream(object):
    """Opens a recording stream as a generator yielding the audio chunks."""
    def __init__(self, rate, chunk):
        self._rate = rate
        self._chunk = chunk
        # Create a thread-safe buffer of audio data
        self._buff = queue.Queue()
        self._closed = True # stream state

    def __enter__(self):
        self._closed = False # open the stream
        return self

    def __exit__(self, type, value, traceback):
        self._closed = True # close the stream

    def generator(self):
        # generate audio chunks from the mic
        with sd.InputStream(samplerate=self._rate, channels=1, dtype='int16', blocksize=self._chunk) as stream:
            while not self._closed:
                data, overflowed = stream.read(self._chunk) # read a chuck of audio
                if overflowed:
                    print("Audio buffer overflowed") # notify if buffer overflow
                self._buff.put(data.tobytes()) # put data into queue
                yield self._buff.get() # yield audio data from the queue

def listen_print_loop(responses):
    # Process and print the transcription results as they are received.
    num_chars_printed = 0 # Track the number of characters printed to handle overwrites
    for response in responses:
        if not response.results:
            continue

        result = response.results[0] # get the first result
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript # get the transcript
        overwrite_chars = ' ' * (num_chars_printed - len(transcript)) # overwrite the characters

        if not result.is_final:
            num_chars_printed = len(transcript) # update the number of characters printed
        else:
            print(transcript + overwrite_chars)  # Print the final transcript
            response=chat.send_message(transcript)
            print(response.text)
            synthesize_text(response.text)
            num_chars_printed = 0 # reset the number of characters printed



@app.route('/transcribe')
def transcribe_stream():
    # Endpoint to start transcribing audio from the microphone
    client = speech.SpeechClient() # Initialize the Google Cloud Speech client

    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="en-US", # Set the audio encoding, sample rate, and language
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True,
    )

    with MicrophoneStream(RATE, CHUNK) as stream:
        audio_generator = stream.generator()
        requests = (speech.StreamingRecognizeRequest(audio_content=content)
                    for content in audio_generator)

        responses = client.streaming_recognize(streaming_config, requests)

        try:
            listen_print_loop(responses)
        except Exception as e:
            print(f"Error: {e}")

    return jsonify({"status": "transcription completed"})



def synthesize_text(text):
    """Synthesizes speech from the input string of text."""

    client = texttospeech.TextToSpeechClient()
    input_text = texttospeech.SynthesisInput(text=text)


    voice = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Standard-I",
        ssml_gender=texttospeech.SsmlVoiceGender.MALE,
    )
    '''voices = client.list_voices()
    for voice in voices.voices:
    # Display the voice's name. Example: tpc-vocoded
        print(f"Name: {voice.name}")
        # Display the supported language codes for this voice. Example: "en-US"
        for language_code in voice.language_codes:
            print(f"Supported language: {language_code}")
        ssml_gender = texttospeech.SsmlVoiceGender(voice.ssml_gender)
        print(f"SSML Voice Gender: {ssml_gender.name}")
        print(f"Natural Sample Rate Hertz: {voice.natural_sample_rate_hertz}\n") '''

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.LINEAR16,
        #speaking_rate=1.5
    )

    response = client.synthesize_speech(
        request={"input": input_text, "voice": voice, "audio_config": audio_config}
    )

    audio_data=np.frombuffer(response.audio_content, dtype=np.int16)
    sd.play(audio_data, samplerate=24000) #24000
    sd.wait()



if __name__ == '__main__':
    app.run(debug=True)